---
title: 数据库优化方案
date: 2019-02-22 11:47:00
tags:
    - 数据库
categories: 数据库
---

# SQL优化方案
[参考博客](https://mp.weixin.qq.com/s/DBeVzJyR9_PXnoAIfJiHfg)

## 优化的哲学
### 优化可能带来的影响

- 优化不总是对一个单纯的环境进行，还很可能是一个复杂的已投产的系统；
- 优化手段本来就有很大的风险，只不过你没能力意识到和预见到；
- 任何的技术可以解决一个问题，但必然存在带来一个问题的风险；
- 对于优化来说解决问题而带来的问题，控制在可接受的范围内才是有成果；
- 保持现状或出现更差的情况都是失败！

### 优化的需求
- 稳定性和业务可持续性，通常比性能更重要；
- 优化不可避免涉及到变更，变更就有风险；
- 优化使性能变好，维持和变差是等概率事件；
- 切记优化，应该是各部门协同，共同参与的工作，任何单一部门都不能对数据库进行优化！

所以优化工作，是由业务需要驱使的！

### 优化参与
在进行数据库优化时，应由数据库管理员、业务部门代表、应用程序架构师、应用程序设计人员、应用程序开发人员、硬件及系统管理员、存储管理员等，业务相关人员共同参与。 

## 优化思路
### 优化对象

在数据库优化上有两个主要方面：即安全与性能。

- 安全->数据可持续性
- 性能->数据的高性能访问

### 优化的范围

- 存储、主机和操作系统方面：
  - 主机架构稳定性；
  - I/O规划及配置；
  - Swap交换分区；
  - OS内核参数和网络问题。
- 应用程序方面：
  - 应用程序稳定性；
  - SQL语句性能；
  - 串行访问资源；
  - 能欠佳会话管理；
  - 这个应用适不适合用MySQL。
- 数据库优化方面：
  - 内存；
  - 数据库结构（物理&逻辑）；
  - 实例配置。

> 不管是设计系统、定位问题还是优化，都可以按照这个顺序执行。

### 优化维度

数据库优化维度有四个：

硬件、系统配置、数据库表结构、SQL及索引。

![](https://minios.strongsickcat.com/dinghuang-blog-picture/9bc4cb9fgy1g0cvkxgfrpj20iw09yad5.jpg)

优化选择：


优化成本：硬件>系统配置>数据库表结构>SQL及索引。

优化效果：硬件<系统配置<数据库表结构<SQL及索引。

## 优化工具
### 数据库层面

检查问题常用工具：

```
1）MySQL

2）msyqladmin：MySQL客户端，可进行管理操作

3）mysqlshow：功能强大的查看shell命令

4）show [SESSION | GLOBAL] variables：查看数据库参数信息

5）SHOW [SESSION | GLOBAL] STATUS：查看数据库的状态信息

6）information_schema：获取元数据的方法

7）SHOW ENGINE INNODB STATUS：Innodb引擎的所有状态

8）SHOW PROCESSLIST：查看当前所有连接session状态

9）explain：获取查询语句的执行计划

10）show index：查看表的索引信息

11）slow-log：记录慢查询语句

12）mysqldumpslow：分析slowlog文件的
```

不常用但好用的工具：
```
1）Zabbix：监控主机、系统、数据库（部署zabbix监控平台）

2）pt-query-digest：分析慢日志

3）MySQL slap：分析慢日志

4）sysbench：压力测试工具

5）MySQL profiling：统计数据库整体状态工具    

6）Performance Schema：MySQL性能状态统计的数据

7）workbench：管理、备份、监控、分析、优化工具（比较费资源）
```

> [关于Zabbix参考](http://www.cnblogs.com/clsn/p/7885990.html)

### 数据库层面问题解决思路

一般应急调优的思路：针对突然的业务办理卡顿，无法进行正常的业务处理，需要立马解决的场景。
```
1）show processlist；

2）explain  select id ,name from stu where name='clsn'; # ALL  id name age  sex；

select id,name from stu  where id=2-1 函数 结果集>30；show index from table；

3）通过执行计划判断，索引问题（有没有、合不合理）或者语句本身问题；

4）show status  like '%lock%';    # 查询锁状态

kill SESSION_ID;   # 杀掉有问题的session。
```
常规调优思路：针对业务周期性的卡顿，例如在每天10-11点业务特别慢，但是还能够使用，过了这段时间就好了。
```
1）查看slowlog，分析slowlog，分析出查询慢的语句；

2）按照一定优先级，一个一个排查所有慢语句；

3）分析top SQL，进行explain调试，查看语句执行时间；

4）调整索引或语句本身。
```

### 系统层面
**Cpu方面**
```
vmstat、sar top、htop、nmon、mpstat；
```
**内存**
```
free、ps-aux；
```
IO设备（磁盘、网络）
```
iostat、ss、netstat、iptraf、iftop、lsof；
```
**vmstat命令说明**
```
1）Procs：r显示有多少进程正在等待CPU时间。b显示处于不可中断的休眠的进程数量。在等待I/O。

2）Memory：swpd显示被交换到磁盘的数据块的数量。未被使用的数据块，用户缓冲数据块，用于操作系统的数据块的数量。

3）Swap：操作系统每秒从磁盘上交换到内存和从内存交换到磁盘的数据块的数量。s1和s0最好是0。

4）Io：每秒从设备中读入b1的写入到设备b0的数据块的数量。反映了磁盘I/O。

5）System：显示了每秒发生中断的数量（in）和上下文交换（cs）的数量。

6）Cpu：显示用于运行用户代码，系统代码，空闲，等待I/O的Cpu时间。
```
**iostat命令说明**
```
实例命令：iostat -dk 1 5

　　　　   iostat -d -k -x 5 （查看设备使用率（%util）和响应时间（await））

1）tps：该设备每秒的传输次数。“一次传输”意思是“一次I/O请求”。多个逻辑请求可能会被合并为“一次I/O请求”。

2）iops ：硬件出厂的时候，厂家定义的一个每秒最大的IO次数

3）"一次传输"请求的大小是未知的。

4）kB_read/s：每秒从设备（drive expressed）读取的数据量；

5）KB_wrtn/s：每秒向设备（drive expressed）写入的数据量；

6）kB_read：读取的总数据量；

7）kB_wrtn：写入的总数量数据量；这些单位都为Kilobytes。
```

### 系统层面问题解决办法
你认为到底负载高好，还是低好呢？在实际的生产中，一般认为Cpu只要不超过90%都没什么问题。



当然不排除下面这些特殊情况：

**Cpu负载高，IO负载低**
```
1）内存不够；

2）磁盘性能差；

3）SQL问题--->去数据库层，进一步排查SQL 问题；

4）IO出问题了（磁盘到临界了、raid设计不好、raid降级、锁、在单位时间内tps过高）；

5）tps过高：大量的小数据IO、大量的全表扫描。
```
**IO负载高，Cpu负载低**
```
1）大量小的IO写操作：

autocommit，产生大量小IO；IO/PS，磁盘的一个定值，硬件出厂的时候，厂家定义的一个每秒最大的IO次数。

2）大量大的IO 写操作：SQL问题的几率比较大
```
**IO和cpu负载都很高**
```
硬件不够了或SQL存在问题。
```

## 基础优化
### 优化思路
**定位问题点吮吸**：硬件-->系统-->应用-->数据库-->架构（高可用、读写分离、分库分表）。

**处理方向**：明确优化目标、性能和安全的折中、防患未然。

### 硬件优化
**主机方面**
```
根据数据库类型，主机CPU选择、内存容量选择、磁盘选择：

1）平衡内存和磁盘资源；

2）随机的I/O和顺序的I/O；

3）主机 RAID卡的BBU（Battery Backup Unit）关闭。
```
**CPU的选择**
```
CPU的两个关键因素：核数、主频

根据不同的业务类型进行选择：

1）CPU密集型：计算比较多，OLTP - 主频很高的cpu、核数还要多

2）IO密集型：查询比较，OLAP - 核数要多，主频不一定高的
```
**内存的选择**
```
OLAP类型数据库，需要更多内存，和数据获取量级有关。

OLTP类型数据一般内存是Cpu核心数量的2倍到4倍，没有最佳实践。
```
**存储方面**
```
1）根据存储数据种类的不同，选择不同的存储设备；

2）配置合理的RAID级别（raid5、raid10、热备盘）；

3）对与操作系统来讲，不需要太特殊的选择，最好做好冗余（raid1）（ssd、sas、sata）。

4）raid卡：

       主机raid卡选择：

           实现操作系统磁盘的冗余（raid1）；

           平衡内存和磁盘资源；

           随机的I/O和顺序的I/O；

           主机raid卡的BBU（Battery Backup Unit）要关闭。
```
网络设备方面
```
使用流量支持更高的网络设备（交换机、路由器、网线、网卡、HBA卡）
```

> 注意：以上这些规划应该在初始设计系统时就应该考虑好。

### 服务器硬件优化
```
1）物理状态灯

2）自带管理设备：远程控制卡（FENCE设备：ipmi ilo idarc）、开关机、硬件监控。

3）第三方的监控软件、设备（snmp、agent）对物理设施进行监控。

4）存储设备：自带的监控平台。EMC2（hp收购了）、 日立（hds）、IBM低端OEM hds、高端存储是自己技术，华为存储。
```
### 系统优化
**Cpu**
```
基本不需要调整，在硬件选择方面下功夫即可。
```
**内存**
```
基本不需要调整，在硬件选择方面下功夫即可。
```
**SWAP**
```
MySQL尽量避免使用swap。

阿里云的服务器中默认swap为0。
```
**IO**
```
raid、no lvm、ext4或xfs、ssd、IO调度策略。
```
**Swap调整(不使用swap分区)**
```
/proc/sys/vm/swappiness的内容改成0（临时），/etc/sysctl. conf上添加vm.swappiness=0（永久）
```
这个参数决定了Linux是倾向于使用swap，还是倾向于释放文件系统cache。在内存紧张的情况下，数值越低越倾向于释放文件系统cache。



当然，这个参数只能减少使用swap的概率，并不能避免Linux使用swap。



**修改MySQL的配置参数``innodb_flush_ method``，开启O_DIRECT模式**：



这种情况下，InnoDB的buffer pool会直接绕过文件系统cache来访问磁盘，但是redo log依旧会使用文件系统cache。



值得注意的是，Redo log是覆写模式的，即使使用了文件系统的cache，也不会占用太多。

**IO调度策略**
```
#echo deadline>/sys/block/sda/queue/scheduler   临时修改为deadline
```
永久修改
```
vi /boot/grub/grub.conf

更改到如下内容:

kernel /boot/vmlinuz-2.6.18-8.el5 ro root=LABEL=/ elevator=deadline rhgb quiet
```

### 系统参数调整
**Linux系统内核参数优化**
```
vim/etc/sysctl.conf

net.ipv4.ip_local_port_range = 1024 65535：# 用户端口范围

net.ipv4.tcp_max_syn_backlog = 4096 

net.ipv4.tcp_fin_timeout = 30 

fs.file-max=65535：# 系统最大文件句柄，控制的是能打开文件最大数量  
```
**用户限制参数（MySQL可以不设置以下配置）**
```
vim/etc/security/limits.conf 

* soft nproc 65535

* hard nproc 65535

* soft nofile 65535

* hard nofile 65535
```
### 应用优化
业务应用和数据库应用独立；


**防火墙**：iptables、selinux等其他无用服务（关闭）：
```
chkconfig --level 23456 acpid off

chkconfig --level 23456 anacron off

chkconfig --level 23456 autofs off

chkconfig --level 23456 avahi-daemon off

chkconfig --level 23456 bluetooth off

chkconfig --level 23456 cups off

chkconfig --level 23456 firstboot off

chkconfig --level 23456 haldaemon off

chkconfig --level 23456 hplip off

chkconfig --level 23456 ip6tables off

chkconfig --level 23456 iptables  off

chkconfig --level 23456 isdn off

chkconfig --level 23456 pcscd off

chkconfig --level 23456 sendmail  off

chkconfig --level 23456 yum-updatesd  off
```
安装图形界面的服务器不要启动图形界面runlevel 3。 



另外，思考将来我们的业务是否真的需要MySQL，还是使用其他种类的数据库。用数据库的最高境界就是不用数据库。

## 数据库优化
SQL优化方向：执行计划、索引、SQL改写。


架构优化方向：高可用架构、高性能架构、分库分表。

### 数据库参数优化
**调整**

实例整体（高级优化，扩展）：
```
thread_concurrency：# 并发线程数量个数

sort_buffer_size：# 排序缓存

read_buffer_size：# 顺序读取缓存

read_rnd_buffer_size：# 随机读取缓存

key_buffer_size：# 索引缓存

thread_cache_size：# (1G—>8, 2G—>16, 3G—>32, >3G—>64)
```
**连接层（基础优化）**
设置合理的连接客户和连接方式：
```
max_connections           # 最大连接数，看交易笔数设置    

max_connect_errors        # 最大错误连接数，能大则大

connect_timeout           # 连接超时

max_user_connections      # 最大用户连接数

skip-name-resolve         # 跳过域名解析

wait_timeout              # 等待超时

back_log                  # 可以在堆栈中的连接数量
```
**SQL层（基础优化）**
query_cache_size： 查询缓存  >>>  OLAP类型数据库,需要重点加大此内存缓存，但是一般不会超过GB。

对于经常被修改的数据，缓存会立马失效。

我们可以实用内存数据库（redis、memecache），替代他的功能。

**存储引擎层（innodb基础优化参数）**
```
default-storage-engine

innodb_buffer_pool_size       # 没有固定大小，50%测试值，看看情况再微调。但是尽量设置不要超过物理内存70%

innodb_file_per_table=(1,0)

innodb_flush_log_at_trx_commit=(0,1,2) # 1是最安全的，0是性能最高，2折中

binlog_sync

Innodb_flush_method=(O_DIRECT, fdatasync)

innodb_log_buffer_size           # 100M以下

innodb_log_file_size               # 100M 以下

innodb_log_files_in_group       # 5个成员以下,一般2-3个够用（iblogfile0-N）

innodb_max_dirty_pages_pct   # 达到百分之75的时候刷写 内存脏页到磁盘。

log_bin

max_binlog_cache_size                     # 可以不设置

max_binlog_size                               # 可以不设置

innodb_additional_mem_pool_size     #小于2G内存的机器，推荐值是20M。32G内存以上100M
```

## SQL语句优化
[原文博客](https://juejin.im/post/5aa7703c6fb9a028c8128739)
1. 对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。
2. 应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描
```
 select id from t where num is null;
```
可以在 num 上设置默认值 0,确保表中 num 列没有 null 值，然后这样查询：
```
select id from t where num=0;
```
3. 应尽量避免在 where 子句中使用!=或<>操作符，否则将引擎放弃使用索引而进行全表扫描。
4. 应尽量避免在 where 子句中使用 or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描
```
select id from t where num=10 or num=20;
```
可以这样查询
```
select id from t where num=10;
select id from t where num=20;
```
5. in 和 not in 也要慎用，否则会导致全表扫描，如：
```
select id from t where num in(1,2,3);
```
对于连续的数值，能用 between 就不要用 in 了：
```
select id from t where num between 1 and 3;
```
6. 下面的查询也将导致全表扫描：
```
select id from t where name like '%c%';
```
若要提高效率，可以考虑[全文检索](https://www.jianshu.com/p/c48106149b6a)。
7. 如果在 where 子句中使用参数，也会导致全表扫描。因为 SQL 只有在运行时才会解析局部变量，但优 化程序不能将访问计划的选择推迟到运行时;它必须在编译时进行选择。然 而，如果在编译时建立访问计 划，变量的值还是未知的，因而无法作为索引选择的输入项。如下面语句将进行全表扫描：
```
select id from t where num=@num ;
```
可以改为强制查询使用索引：
```
select id from t with(index(索引名)) where num=@num ;
```
8. 应尽量避免在 where 子句中对字段进行表达式操作， 这将导致引擎放弃使用索引而进行全表扫描。
```
select id from t where num/2=100;
```
可以这样查询：
```
select id from t where num=100*2;
```
9. 应尽量避免在 where 子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。如：
```
select id from t where substring(name,1,3)='abc';#name 以 abc 开头的 id
```
应改为：
```
select id from t where name like 'abc%';
```
10. 不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用 索引。
11. 在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件 时才能保证系统使用该索引， 否则该索引将不会 被使用， 并且应尽可能的让字段顺序与索引顺序相一致。
12. 不要写一些没有意义的查询，如需要生成一个空表结构：
```
select col1,col2 into #t from t where 1=0;
```
这类代码不会返回任何结果集，但是会消耗系统资源的，应改成这样：
```
create table #t(…);
```
13. 很多时候用 exists 代替 in 是一个好的选择：
```
select num from a where num in(select num from b);
```
用下面的语句替换：
```
select num from a where exists(select 1 from b where num=a.num);
```
14. 并不是所有索引对查询都有效，SQL 是根据表中数据来进行查询优化的，当索引列有大量数据重复时， SQL 查询可能不会去利用索引，如一表中有字段 sex,male、female 几乎各一半，那么即使在 sex 上建 了索引也对查询效率起不了作用。
15. 索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过 6 个，若太多则应考虑一些不常使用到的列上建的索引是否有必要。
16. 应尽可能的避免更新 clustered 索引数据列， 因为 clustered 索引数据列的顺序就是表记录的物理存储顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源。若应用系统需要频繁更新 clustered 索引数据列，那么需要考虑是否应将该索引建为 clustered 索引。
17. 尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并 会增加存储开销。这是因为引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言 只需要比较一次就够了。
18. 尽可能的使用 ``varchar/nvarchar`` 代替 ``char/nchar`` , 因为首先变长字段存储空间小， 可以节省存储空间， 其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。
19. 任何地方都不要使用 ``select * from t`` ,用具体的字段列表代替“*”,不要返回用不到的任何字段。
20. 尽量使用表变量来代替临时表。如果表变量包含大量数据，请注意索引非常有限(只有主键索引)。
21. 避免频繁创建和删除临时表，以减少系统表资源的消耗。
22. 临时表并不是不可使用，适当地使用它们可以使某些例程更有效，例如，当需要重复引用大型表或常用。 表中的某个数据集时。但是，对于一次性事件， 最好使用导出表。
23. 在新建临时表时，如果一次性插入数据量很大，那么可以使用 ``select into`` 代替 ``create table``,避免造成大量 log ,以提高速度;如果数据量不大，为了缓和系统表的资源，应先 ``create table``,然后 ``insert``。
24. 如果使用到了临时表， 在存储过程的最后务必将所有的临时表显式删除， 先 ``truncate table`` ,然后 ``drop table`` ,这样可以避免系统表的较长时间锁定。
25. 尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过 1 万行，那么就应该考虑改写。
26. 使用基于游标的方法或临时表方法之前，应先寻找基于集的解决方案来解决问题，基于集的方法通常更有效。
27. 与临时表一样，游标并不是不可使用。对小型数据集使用 ``FAST_FORWARD`` 游标通常要优于其他逐行处理方法，尤其是在必须引用几个表才能获得所需的数据时。在结果集中包括“合计”的例程通常要比使用游标执行的速度快。如果开发时间允许，基于游标的方法和基于集的方法都可以尝试一下，看哪一种方法的效果更好。
28. 在所有的存储过程和触发器的开始处设置 ``SET NOCOUNT ON ``,在结束时设置 ``SET NOCOUNT OFF`` .无需在执行存储过程和触发器的每个语句后向客户端发送``DONE_IN_PROC``消息。
29. 尽量避免大事务操作，提高系统并发能力。 sql 优化方法使用索引来更快地遍历表。 缺省情况下建立的索引是非群集索引，但有时它并不是最佳的。在非群集索引下，数据在物理上随机存放在数据页上。合理的索引设计要建立在对各种查询的分析和预测上。一般来说：

    - 有大量重复值、且经常有范围查询( > ,< ,> =,< =)和 order by、group by 发生的列，可考虑建立集群索引;
    - 经常同时存取多列，且每列都含有重复值可考虑建立组合索引;
    - 组合索引要尽量使关键查询形成索引覆盖，其前导列一定是使用最频繁的列。索引虽有助于提高性能但 不是索引越多越好，恰好相反过多的索引会导致系统低效。用户在表中每加进一个索引，维护索引集合就 要做相应的更新工作。
30. 定期分析表和检查表
```
分析表的语法：ANALYZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tb1_name[, tbl_name]...
```
以上语句用于分析和存储表的关键字分布，分析的结果将可以使得系统得到准确的统计信息，使得SQL能够生成正确的执行计划。如果用户感觉实际执行计划并不是预期的执行计划，执行一次分析表可能会解决问题。在分析期间，使用一个读取锁定对表进行锁定。这对于MyISAM，DBD和InnoDB表有作用。
```
例如分析一个数据表：analyze table table_name

检查表的语法：CHECK TABLE tb1_name[,tbl_name]...[option]...option = {QUICK | FAST | MEDIUM | EXTENDED | CHANGED}
```
检查表的作用是检查一个或多个表是否有错误，CHECK TABLE 对MyISAM 和 InnoDB表有作用，对于MyISAM表，关键字统计数据被更新

CHECK TABLE 也可以检查视图是否有错误，比如在视图定义中被引用的表不存在。
31. 定期优化表。
```
优化表的语法：OPTIMIZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tb1_name [,tbl_name]...
```
如果删除了表的一大部分，或者如果已经对含有可变长度行的表(含有 VARCHAR、BLOB或TEXT列的表)进行更多更改，则应使用OPTIMIZE TABLE命令来进行表优化。这个命令可以将表中的空间碎片进行合并，并且可以消除由于删除或者更新造成的空间浪费，但OPTIMIZE TABLE 命令只对MyISAM、 BDB 和InnoDB表起作用。

```
例如： optimize table table_name
```

> 注意： analyze、check、optimize执行期间将对表进行锁定，因此一定注意要在MySQL数据库不繁忙的时候执行相关的操作。

### 其他
1. 在海量查询时尽量少用格式转换。
2. ORDER BY 和 GROPU BY:使用 ORDER BY 和 GROUP BY 短语，任何一种索引都有助于 SELECT 的性能提高。
3. 任何对列的操作都将导致表扫描，它包括数据库教程函数、计算表达式等等，查询时要尽可能将操作移至等号右边。
4. IN、OR 子句常会使用工作表，使索引失效。如果不产生大量重复值，可以考虑把子句拆开。拆开的子 句中应该包含索引。
5. 只要能满足你的需求，应尽可能使用更小的数据类型：例如使用 MEDIUMINT 代替 INT
6. 尽量把所有的列设置为 NOT NULL,如果你要保存 NULL,手动去设置它，而不是把它设为默认值。
7. 尽量少用 VARCHAR、TEXT、BLOB 类型
8. 如果你的数据只有你所知的少量的几个。最好使用 ENUM 类型
9. 正如 graymice 所讲的那样，建立索引。
10. 合理用运分表与分区表提高数据存放和提取速度。

## 亿级数据下的分库分表方案
[原文](https://www.tuicool.com/articles/2EzuQr7)

### 项目背景
项目背景是企业级的统一消息处理平台，客户数据在5千万加，每分钟处理消息流水1千万，每天消息流水1亿左右。 虽说Mysql单表可以存储10亿级的数据，但这个时候性能非常差，项目中大量的实验证明，Mysql单表容量在500万左右，性能处于最佳状态，此时，Mysql的BTREE索引树高在3～5之间。既然一张表无法搞定，那么就想办法将数据放到多个地方来解决问题吧，于是，数据库分库分表的方案便产生了，目前比较普遍的方案有三个： 分区，分库分表，NoSql/NewSql 。

在实际的项目中，往往是这三种方案的结合来解决问题，目前绝大部分系统的核心数据都是以RDBMS存储为主，NoSql/NewSql存储为辅。

### 分区
首先来了解一下分区方案。

分区表是由多个相关的底层表实现，这些底层表也是由句柄对象表示，所以我们也可以直接访问各个分区，存储引擎管理分区的各个底层表和管理普通表一样（所有的底层表都必须使用相同的存储引擎），分区表的索引只是在各个底层表上各自加上一个相同的索引，从存储引擎的角度来看，底层表和一个普通表没有任何不同，存储引擎也无须知道这是一个普通表还是一个分区表的一部分。这个方案也不错，它对用户屏蔽了sharding的细节，即使查询条件没有sharding column，它也能正常工作（只是这时候性能一般）。不过它的缺点很明显：很多的资源都受到单机的限制，例如连接数，网络吞吐等。如何进行分区，在实际应用中是一个非常关键的要素之一。在我们的项目中，以客户信息为例，客户数据量5000万加，项目背景要求保存客户的银行卡绑定关系，客户的证件绑定关系，以及客户绑定的业务信息。此业务背景下，该如何设计数据库呢。项目一期的时候，我们建立了一张客户业务绑定关系表，里面冗余了每一位客户绑定的业务信息。基本结构大致如下：
![](https://minios.strongsickcat.com/dinghuang-blog-picture/9bc4cb9fgy1g0e1086caaj20fa06m761.jpg)
查询时，对银行卡做索引，业务编号做索引，证件号做索引。随着需求大增多，这张表的索引会达到10个以上。而且客户解约再签约，里面会保存两条数据，只是绑定的状态不同。假设我们有5千万的客户，5个业务类型，每位客户平均2张卡，那么这张表的数据量将会达到惊人的5亿，事实上我们系统用户量还没有过百万时就已经不行了。mysql数据库中的数据是以文件的形势存在磁盘上的，默认放在/mysql/data下面（可以通过my.cnf中的datadir来查看）， 一张表主要对应着三个文件，一个是frm存放表结构的，一个是myd存放表数据的，一个是myi存表索引的。这三个文件都非常的庞大，尤其是.myd文件，快5个G了。 下面进行第一次分区优化 ，Mysql支持的分区方式有四种：
![](https://minios.strongsickcat.com/dinghuang-blog-picture/9bc4cb9fgy1g0e11m0q1wj20fa066tbt.jpg)
在我们的项目中，range分区和list分区没有使用场景，如果基于绑定编号做range或者list分区，绑定编号没有实际的业务含义，无法通过它进行查询，因此，我们就剩下 HASH 分区和 KEY 分区了， HASH 分区仅支持int类型列的分区，且是其中的一列。看看我们的库表结构，发现没有哪一列是int类型的，如何做分区呢？可以增加一列，绑定时间列，将此列设置为int类型，然后按照绑定时间进行分区，将每一天绑定的用户分到同一个区里面去。这次优化之后，我们的插入快了许多，但是查询依然很慢，为什么，因为在做查询的时候，我们也只是根据银行卡或者证件号进行查询，并没有根据时间查询，相当于每次查询，mysql都会将所有的分区表查询一遍。

然后进行第二次方案优化，既然hash分区和key分区要求其中的一列必须是int类型的，那么创造出一个int类型的列出来分区是否可以。分析发现，银行卡的那串数字有秘密。银行卡一般是16位到19位不等的数字串，我们取其中的某一位拿出来作为表分区是否可行呢，通过分析发现，在这串数字中，其中确实有一位是0到9随机生成的，不同的卡串长度，这一位不同，绝不是最后一位，最后位数字一般都是校验位，不具有随机性。我们新设计的方案，基于银行卡号+随机位进行KEY分区，每次查询的时候，通过计算截取出这位随机位数字，再加上卡号，联合查询，达到了分区查询的目的，需要说明的是，分区后，建立的索引，也必须是分区列，否则的话，Mysql还是会在所有的分区表中查询数据。那么通过银行卡号查询绑定关系的问题解决了，那么证件号呢，如何通过证件号来查询绑定关系。前面已经讲过，做索引一定是要在分区健上进行，否则会引起全表扫描。我们再创建了一张新表，保存客户的证件号绑定关系，每位客户的证件号都是唯一的，新的证件号绑定关系表里，证件号作为了主键，那么如何来计算这个分区健呢，客户的证件信息比较庞杂，有身份证号，港澳台通行证，机动车驾驶证等等，如何在无序的证件号里找到分区健。为了解决这个问题，我们将证件号绑定关系表一分为二，其中的一张表专用于保存身份证类型的证件号，另一张表则保存其他证件类型的证件号，在身份证类型的证件绑定关系表中，我们将身份证号中的月数拆分出来作为了分区健，将同一个月出生的客户证件号保存在同一个区，这样分成了12个区，其他证件类型的证件号，数据量不超过10万，就没有必要进行分区了。这样每次查询时，首先通过证件类型确定要去查询哪张表，再计算分区健进行查询。

作了分区设计之后，保存2000万用户数据的时候，银行卡表的数据保存文件就分成了10个小文件，证件表的数据保存文件分成了12个小文件，解决了这两个查询的问题，还剩下一个问题就是，业务编号呢，怎么办，一个客户有多个签约业务，如何进行保存，这时候，采用分区的方案就不太合适了，它需要用到分表的方案。

### 分库分表
如何进行分库分表，目前互联网上有许多的版本，比较知名的一些方案：

- 阿里的[TDDL](https://github.com/alibaba/tb_tddl)，[DRDS](https://cn.aliyun.com/product/drds)和[cobar](https://github.com/alibaba/cobar)
- [京东金融的sharding-jdbc](https://yq.aliyun.com/articles/658786)
- 民间组织的[MyCAT](https://github.com/MyCATApache/Mycat-Server)
- 360的[Atlas](https://github.com/Qihoo360/Atlas)
- 美团的[zebra](https://github.com/Meituan-Dianping/Zebra)

其他比如网易，58，京东等公司都有自研的中间件。

![](https://minios.strongsickcat.com/dinghuang-blog-picture/9bc4cb9fgy1g0f0ubx3knj20oc0fd45s.jpg)
百花齐放的景象。但是这么多的分库分表中间件方案，归总起来，就两类： client模式和proxy模式 。

**client模式**
![](https://minios.strongsickcat.com/dinghuang-blog-picture/9bc4cb9fgy1g0e1osp6e3j20fa0c2ta5.jpg)

**proxy模式**
![](https://minios.strongsickcat.com/dinghuang-blog-picture/9bc4cb9fgy1g0e1v26i8nj20fa0gxmyt.jpg)

无论是client模式，还是proxy模式，几个核心的步骤是一样的：SQL解析，重写，路由，执行，结果归并。个人比较倾向于采用client模式，它架构简单，性能损耗也比较小，运维成本低。如果在项目中引入mycat或者cobar，他们的单机模式无法保证可靠性，一旦宕机则服务就变得不可用，你又不得不引入HAProxy来实现它的高可用集群部署方案， 为了解决HAProxy的高可用问题，又需要采用Keepalived来实现。
![](https://minios.strongsickcat.com/dinghuang-blog-picture/9bc4cb9fgy1g0e2eu3bjvj20fa0gy0zk.jpg)

我们在项目中放弃了这个方案，采用了shardingjdbc的方式。回到刚才的业务问题，如何对业务类型进行分库分表。分库分表第一步也是最重要的一步，即sharding column的选取，sharding column选择的好坏将直接决定整个分库分表方案最终是否成功。而sharding column的选取跟业务强相关。在我们的项目场景中，sharding column无疑最好的选择是业务编号。通过业务编号，将客户不同的绑定签约业务保存到不同的表里面去，查询时，根据业务编号路由到相应的表中进行查询，达到进一步优化sql的目的。

前面我们讲到了基于客户签约绑定业务场景的数据库优化，下面我们再聊一聊，对于海量数据的保存方案。

### 垂直拆分
#### 垂直分表
也就是“大表拆小表”，基于列字段进行的。一般是表中的字段较多，将不常用的， 数据较大，长度较长（比如text类型字段）的拆分到“扩展表“。 一般是针对那种几百列的大表，也避免查询时，数据量太大造成的“跨页”问题。

#### 垂直分库
垂直分库在“微服务”盛行的今天已经非常普及了。基本的思路就是按照业务模块来划分出不同的数据库，而不是像早期一样将所有的数据表都放到同一个数据库中。如下图：
![](https://minios.strongsickcat.com/dinghuang-blog-picture/9bc4cb9fgy1g0ezns2ifaj20bf08kgml.jpg)
**优点**

数据库往往最容易成为应用系统的瓶颈，而数据库本身属于“有状态”的，相对于 Web 和应用服务器来讲，是比较难实现“横向扩展”的。数据库的连接资源比较宝贵且单机处理能力也有限，在高并发场景下，垂直分库一定程度上能够突破 IO、连接数及单机硬件资源的瓶颈，是大型分布式系统中优化数据库架构的重要手段。

**缺点**

- 跨库 join 的问题
- 跨库事务（分布式事务）的问题

**解决方式**

- 全局表 
  - 所谓全局表，就是有可能系统中所有模块都可能会依赖到的一些表。比较类似我们理解的“数据字典”。为了避免跨库 join 查询，我们可以将这类表在其他每个数据库中均保存一份。同时，这类数据通常也很少发生修改（甚至几乎不会），所以也不用太担心“一致性”问题。
- 字段冗余 
  - 这是一种典型的反范式设计，在互联网行业中比较常见，通常是为了性能来避免 join 查询。
- 数据同步
  - 定时 A 库中的 tab_a 表和 B 库中 tbl_b 有关联，可以定时将指定的表做同步。当然，同步本来会对数据库带来一定的影响，需要性能影响和数据时效性中取得一个平衡。这样来避免复杂的跨库查询。例如ETL工具。
- 系统层组装
  - 在系统层面，通过调用不同模块的组件或者服务，获取到数据并进行字段拼装。说起来很容易，但实践起来可真没有这么简单，尤其是数据库设计上存在问题但又无法轻易调整的时候。



对于每分钟要处理近1000万的流水，每天流水近1亿的量，如何高效的写入和查询，是一项比较大的挑战。还是老办法，分库分表分区，读写分离，只不过这一次，我们先分表，再分库，最后分区。我们将消息流水按照不同的业务类型进行分表，相同业务的消息流水进入同一张表，分表完成之后，再进行分库。我们将流水相关的数据单独保存到一个库里面去，这些数据，写入要求高，查询和更新到要求低，将它们和那些更新频繁的数据区分开。分库之后，再进行分区。
![](https://minios.strongsickcat.com/dinghuang-blog-picture/9bc4cb9fgy1g0e30hgeqaj20fa06c75g.jpg)
这是基于业务垂直度进行的分库操作，垂直分库就是根据业务耦合性，将关联度低的不同表存储在不同的数据库，以达到系统资源的饱和利用率。这样的分库方案结合应用的微服务治理，每个微服务系统使用独立的一个数据库。将不同模块的数据分库存储，模块间不能进行相互关联查询，如果有，要么通过数据冗余解决，要么通过应用代码进行二次加工进行解决。若不能杜绝跨库关联查询，则将小表到数据冗余到大数据量大库里去。假如，流水大表中查询需要关联获得渠道信息，渠道信息在基础管理库里面，那么，要么在查询时，代码里二次查询基础管理库中的渠道信息表，要么将渠道信息表冗余到流水大表中。

将每天过亿的流水数据分离出去之后，流水库中单表的数据量还是太庞大，我们将单张流水表继续分区，按照一定的业务规则，（一般是查询索引列）将单表进行分区，一个表编程N个表，当然这些变化对应用层是无法感知的。
![](https://minios.strongsickcat.com/dinghuang-blog-picture/9bc4cb9fgy1g0e5r0z2zoj20fa0lgjw2.jpg)
分区表的设置，一般是以查询索引列进行分区，例如，对于流水表A，查询需要根据手机号和批次号进行查询，所以我们在创建分区的时候，就选择以手机号和批次号进行分区，这样设置后，查询都会走索引，每次查询Mysql都会根据查询条件计算出来，数据会落在那个分区里面，直接到对应的分区表中检索即可，避免了全表扫描。

对于每天流水过亿的数据，当然是要做历史表进行数据迁移的工作了。客户要求流水数据需要保存半年的时间，有的关键流水需要保存一年。删数据是不可能的了，也跑不了路，虽然当时非常有想删数据跑路的冲动。其实即时是删数据也是不太可能的了，delete的拙劣表演先淘汰了，truncate也快不了多少，我们采用了一种比较巧妙方法，具体步骤如下：

1. 创建一个原表一模一样的临时表1 ``create table test_a_serial_1 like test_a_serial``;
2. 将原表命名为临时表2 ``alter table test_a_serial rename test_a_serial_{date}``;
3. 将临时表1改为原表 ``alter table able test_a_serial_1 rename able test_a_serial``; 此时，当日流水表就是一张新的空表了，继续保存当日的流水，而临时表2则保存的是昨天的数据和部分今天的数据，临时表2到名字中的date时间是通过计算获得的昨日的日期；每天会产生一张带有昨日日期的临时表2，每个表内的数据大约是有1000万。
4. 将当日表中的历史数据迁移到昨日流水表中去 这样的操作都是用的定时任务进行处理，定时任务触发一般会选择凌晨12点以后，这个操作即时是几秒内完成，也有可能会有几条数据落入到当日表中去。因此我们最后还需要将当日表内的历史流水数据插入到昨日表内； ``insert into test_a_serial_{date}(cloumn1,cloumn2….) select(cloumn1,cloumn2….) from test_a_serial where LEFT(create_time,8) > CONCAT(date); commit``;

如此，便完成了流水数据的迁移；

根据业务需要，有些业务数据需要保存半年，超过半年的进行删除,在进行删除的时候，就可以根据表名中的_{date}筛选出大于半年的流水直接删表；

半年的时间，对于一个业务流水表大约就会有180多张表，每张表又有20个分区表，那么如何进实时计算统计行查询呢？由于我们的项目对于流水的查询实时性要求不是特别高，因此我们在做查询时，进行了根据查询时间区间段进行路由查询的做法。大致做法时，根据客户选择的时间区间段，带上查询条件，分别去时间区间段内的每一张表内查询，将查询结果保存到一张临时表内，然后，再去查询临时表获得最终的查询结果。

半年的时间，对于一个业务流水表大约就会有180多张表，每张表又有20个分区表，那么如何进行查询呢？由于我们的项目对于流水的查询实时性要求不是特别高，因此我们在做查询时，进行了根据查询时间区间段进行路由查询的做法。大致做法时，根据客户选择的时间区间段，带上查询条件，分别去时间区间段内的每一张表内查询，将查询结果保存到一张临时表内，然后，再去查询临时表获得最终的查询结果。

以上便是我们面对大数据量的场景下，数据库层面做的相应的优化，一张每天一亿的表，经过拆分后，每个表分区内的数据在500万左右。

### 水平拆分
#### 水平分表
针对数据量巨大的单张表（比如订单表），按照某种规则（RANGE,HASH取模等），切分到多张表里面去。 但是这些表还是在同一个库中，所以库级别的数据库操作还是有IO瓶颈。不建议采用。
![](https://minios.strongsickcat.com/dinghuang-blog-picture/9bc4cb9fgy1g0ezurxr0cj20bk07hwhl.jpg)
某种意义上来讲，有些系统中使用的“冷热数据分离”（将一些使用较少的历史数据迁移到其他的数据库中。而在业务功能上，通常默认只提供热点数据的查询），也是类似的实践。在高并发和海量数据的场景下，分库分表能够有效缓解单机和单库的性能瓶颈和压力，突破 IO、连接数、硬件资源的瓶颈。当然，投入的硬件成本也会更高。同时，这也会带来一些复杂的技术问题和挑战（例如：跨分片的复杂查询，跨分片事务等）。

#### 水平分库分表
将单张表的数据切分到多个服务器上去，每个服务器具有相应的库与表，只是表中数据集合不同。 水平分库分表能够有效的缓解单机和单库的性能瓶颈和压力，突破IO、连接数、硬件资源等的瓶颈。

**水平分库分表切分规则**
- RANGE
 - 从0到10000一个表，10001到20000一个表；
- [HASH取模](http://www.uml.org.cn/sjjm/201412301.asp?artid=15741)
 - 一个商场系统，一般都是将用户，订单作为主表，然后将和它们相关的作为附表，这样不会造成跨库事务之类的问题。 取用户id，然后hash取模，分配到不同的数据库上。
- 地理区域
 - 比如按照华东，华南，华北这样来区分业务，七牛云应该就是如此。
- 时间
 - 按照时间切分，就是将6个月前，甚至一年前的数据切出去放到另外的一张表，因为随着时间流逝，这些表的数据 被查询的概率变小，所以没必要和“热数据”放在一起，这个也是“冷热数据分离”。


## 唯一ID方案
这个方案也很多，主流的有那么几种:

- 利用数据库自增ID
  - 优点：最简单。 
  - 缺点：单点风险、单机性能瓶颈。
- 利用数据库集群并设置相应的步长（Flickr方案）
  - 优点：高可用、ID较简洁。 
  - 缺点：需要单独的数据库集群。
- Twitter Snowflake
  - 优点：高性能高可用、易拓展。
  - 缺点：需要独立的集群以及ZK。
- 一大波GUID、Random算法
  - 优点：简单。 
  - 缺点：生成ID较长，有重复几率。
- 带有业务属性的方案： > 时间戳+用户标识码+随机数
  - 优点：方便、成本低。基本无重复的可能。自带分库规则，这里的用户标识码即为用户ID的后四位，在查询的场景下，只需要订单号就可以匹配到相应的库表而无需用户ID，只取四位是希望订单号尽可能的短一些，并且评估下来四位已经足够。可排序，因为时间戳在最前面。
  - 缺点：比如长度稍长，性能要比int/bigint的稍差等。

## 数据迁移
数据库拆分一般是业务发展到一定规模后的优化和重构，为了支持业务快速上线，很难一开始就分库分表，垂直拆分还好办，改改数据源就搞定了，一旦开始水平拆分，数据清洗就是个大问题，为此，我们经历了以下几个阶段。

### 第一阶段
![](https://minios.strongsickcat.com/dinghuang-blog-picture/9bc4cb9fgy1g0f15jmuu7j20j80ibgmv.jpg)
- 数据库双写（事务成功以老模型为准），查询走老模型。
- 每日job数据对账（通过DW），并将差异补平。
- 通过job导历史数据。

### 第二阶段
![](https://minios.strongsickcat.com/dinghuang-blog-picture/9bc4cb9fgy1g0f164jbhbj20j80ewgmg.jpg)
历史数据导入完毕并且数据对账无误。
依然是数据库双写，但是事务成功与否以新模型为准，在线查询切新模型。
每日job数据对账，将差异补平。

### 第三阶段
![](https://minios.strongsickcat.com/dinghuang-blog-picture/9bc4cb9fgy1g0f16or9y7j20j80ibtam.jpg)
- 老模型不再同步写入，仅当订单有终态时才会异步补上。
- 此阶段只有离线数据依然依赖老的模型，并且下游的依赖非常多，待DW改造完就可以完全废除老模型了。

## 报表统计
待我后续更新。